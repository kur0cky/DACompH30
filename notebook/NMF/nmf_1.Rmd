---
title: "nmf_1"
author: "Yutaka Kuroki"
date: "2018/11/5"
output:
  html_document:
    number_sections: true
    fig_caption: true
    toc: true
    toc_float: true
    toc_depth: 2
    fig_width: 7
    theme: cosmo
    highlight: tango
    code_folding: hide
editor_options: 
  chunk_output_type: console
md_extensions: -ascii_identifiers
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,
                      message = FALSE,
                      warning = FALSE,
                      cache = TRUE)
```

```{r import, cache=FALSE}
library(tidyverse)
library(lubridate)
library(dbplyr)
library(dbplot)
library(RPostgreSQL)
library(ggforce)
library(DT)
library(NMF)
library(knitr)
library(minerva)
library(GGally)
library(ggalluvial)

theme_set(theme_bw(base_family = "HiraKakuPro-W3"))
```

```{r connect, cache=FALSE}
conn <- dbConnect(PostgreSQL(),
                  host = scan("connection.txt", what = character())[1],
                  port = scan("connection.txt", what = character())[2], 
                  dbname = scan("connection.txt", what = character())[3], 
                  user = scan("connection.txt", what = character())[4], 
                  password = scan("connection.txt", what = character())[5])

orgn <- conn %>% 
  tbl(from = dbplyr::in_schema("edit", "tv_orgn_program_2")) 
tmp <- conn %>% 
  tbl(from = dbplyr::in_schema("processed", "tv_orgn_p_cv")) 
program <- conn %>% 
  tbl(from = dbplyr::in_schema("processed", "tv_program")) 
ban <- conn %>% 
  tbl(from = dbplyr::in_schema("processed", "bancluster_mst")) 
ban1 <- conn %>% 
  tbl(from = dbplyr::in_schema("sub_mst", "ban_code1_mst")) 
ban2 <- conn %>% 
  tbl(from = dbplyr::in_schema("sub_mst", "ban_code2_mst")) 
prof_data <- conn %>% 
  tbl(from = dbplyr::in_schema("processed", "profiledata"))
prof_mst <- conn %>% 
  tbl(from = dbplyr::in_schema("processed", "profilemaster"))
prof <- prof_data %>% 
  left_join(prof_mst, by = c("qu_genre_code", "question_code", "answer_code"))
sta <- conn %>% 
  tbl(from = dbplyr::in_schema("processed", "sta_mst"))

## CM
jiten <- conn %>% 
  tbl(from = dbplyr::in_schema("processed", "jiten_data"))
brand <- conn %>% 
  tbl(from = dbplyr::in_schema("processed", "m_cm_tv_brand"))
adv <- conn %>% 
  tbl(from = dbplyr::in_schema("processed", "m_cm_tv_advertiser"))

watch_rate <- read_csv("data/processed/watch_rate.csv")

res <- read_rds("data/results_nmf.rds")
res2 <- read_rds("data/results_nmf2.rds")
res <- c(res, res2)
```

# はじめに

テレビ視聴データを用いるにあたって

- テレビ番組を**語句**
- 視聴者を**書き手**

とみなすことによって，テキスト分析の手法や解釈が持ってこれると考えている（勝手に）  
（係り受けに由来するようなものは除く）

# 語句の重み

情報検査，コーパス分析，文章の自動要約などを行うとき，語句（今回の場合はテレビ番組）の重要度を示す重みが必要な場合がある．
**重みの値が大きいほど，その語句（番組）が該当するテキストのキーワードになることを意味する．**
語句の重みに関する指標は多く提案されている

**ブーリアン重み付け**  
対象語句がテキストの中に現れれば1，そうでなければ0

**頻度重み付け**  
対象語句がテキストの中に現れた回数(TF: term frequency)．  
長さが異なる複数のテキストについて分析するときは長さの影響を取り除くため，テキストの長さで調整を行った調整頻度(rTF: relative term frequency)を用いることが多い（今回の分析でもそうした）．
また，対数をとる場合もある

**TF-IDF重み付け**  
$$\text{TF-IDF} = TF * IDF$$  
で定義される．ここでIDF(inverted document frequency)は，語句がどのくらいのテキストに現れているかに関する度合いである．最もシンプルなIDFは次で定義される  
$$\text{IDF}_i = {\rm log}\left(\frac{N}{df_i}\right)$$  
式の中の$df_i$は対象語句$_i$を含むテキストの数，$N$はテキストの総数である．  
IDFを導入するメリットは，汎用的な単語に対するフィルターである．**いくつもの文書で横断的に使われている単語はそんなに重要じゃない**という発想に由来する．

**エントロピー重み付け**  
IDFを単語（番組）がテキスト（視聴者）に現れる（視聴される）確率ととらえ，シャノンのエントロピーによる重み付けを考えることができる

# テレビ視聴におけるTF-IDF

本分析では，テレビ視聴に対するTF-IDFを以下で定義する．
ここで，テレビ番組のインデックスを$i=1,\dots,M$とし，視聴者のインデックスを$j=1,\dots,N$とする．
また，データ期間内に視聴者$j$が番組$i$を見た視聴時間を$w_{i,j}$と表す．

$$
r_j\text{TF-IDF}_{i,j} = r_j \times \text{TF}_{i,j}\times\text{IDF}_{i} =\\
\frac{1}{\sum_{i}w_{i,j}} \times w_{i,j} \times {\rm log}\left(\frac{N}{df_{i}}\right)
$$

# NMF（非負値行列因子分解）

NMFは得られた非負行列$Y$を以下のように二つの非負値行列$H,U$の行列積で近似する．
これは$Y$を複数の基底ベクトルの適当な重み付き和で表そうとしていることに相当する．

$$
Y\simeq HU
$$

**非負値行列の行列積で近似することのメリット**  
NMFでは観測データの中で共起する成分をひとまとめにしたものが基底ベクトルの推定結果になる傾向がある．
また，係数行列の非負性により，係数行列の要素がスパースになる傾向がある．
これは観測ベクトルと近い方向を向いた基底ベクトル以外の係数はできるだけ小さくした方が良い，という直感と一致する．  
テレビ視聴がいくつかの共起パターンの加法で表されることがパターンの減算が物理的なメカニズムから想像しにくいこともメリットの一つである．



本調査では，推定には以下を用いた．

- アルゴリズム : Brunet et al.(2004)．Lee et al.(2001)の改良
- 初期値 : fastICA

Brunet et al. のアルゴリズムはKL距離に基づいた更新式を用いており，これは観測行列の各成分が独立にポアソン分布に従うを仮定した際の最尤推定に相当する．

# データ概要

前節のテレビ視聴におけるTF-IDFの定義に従って番組-視聴者行列$Y$を算出した．また，その過程では以下の前処理を行った．

- program_codeが同一で番組名が異なる（特番など）は同一番組とみなした
- 行和が0になる番組，列和が0になる視聴者を除いた
- 番組名が同一でも放送時間帯が異なる（program_codeが異なる）ものは別番組とみなした

# データ解析

$k$を3~9で変えながら，NMFによる分解とデータ解析を行った

## 結果概要

```{r results_summary}
smr <- sapply(res, function(x) summary(x)) %>% 
  t() %>% 
  as.data.frame()
smr %>% 
  kable()
```

## 基底ベクトルの数について

適切な基底ベクトルの数を考察する

基底ベクトルの数と残差の関係は以下のようになっている．
まだまだ線形で下がっている印象があり，まだまだやってみるべきかも

```{r result_summary}
smr %>% 
  ggplot(aes(rank, residuals))+
  geom_line()+
  geom_point()+
  labs(title = "残差", x = "k")
```

```{r fig1, eval=FALSE}
ggsave("report/fig/rank_resid.png", height=3, width=6)
```

基底ベクトル同士の相関は低くなるはずである．
基底ベクトルの相関係数行列の対角成分以外の成分のうち，その絶対値が最大のものを算出し，基底ベクトルの数との関係を以下にプロットした．  
$k=8$から最大相関係数が跳ね上がっており，適切な$k$は7であると判断できる？？

```{r mic_cor}
mic <- sapply(res, function(x) {
  a <- mine(basis(x))$MIC
  diag(a) <- 0
  return( max(abs(a)) )
  })

cor <- sapply(res, function(x) {
  a <- cor(basis(x))
  diag(a) <- 0
  return( max(abs(a)) )
  })
smr <- smr %>% 
  mutate(cor =  cor) #%>% 
  # mutate(mic = mic)
```

```{r cor_rank_line}
smr %>% 
  ggplot(aes(rank, cor))+
  geom_point()+
  geom_line()+
  labs(x= "k", title = "基底行列の最大相関係数")
```

```{r fig2, eval=FALSE}
ggsave("report/fig/rank_cor.png", height=3, width=6)
```

続いて，MICでも同様の確認を行った  
こちらではまだまだ行けるような気がする

```{r mic_rank_line}
smr %>% 
  ggplot(aes(rank, mic))+
  geom_line()
```


## TOP20{.tabset}

各トピック（基底ベクトル，共起パターン）の性質を解釈するため，トピックへの寄与が高いTOP20番組を示す．  
また，番組名の先頭の数値はstation_codeを示す

```{r pro_mst}
pro_mst <- program %>% 
  count(station_code, program_code, program_name) %>% 
  collect() %>% 
  ungroup() %>% 
  arrange(program_code, desc(n)) %>% 
  group_by(program_code) %>% 
  slice(1) %>% 
  mutate(program_name = str_remove_all(program_name, pattern = " "),
         program_name = str_c(station_code, ".", program_name)) %>% 
  select(-station_code)
```







### 基底ベクトル3個

- 流石に3個は少なすぎたか
- なんとなく分かれてそうではある

```{r table3}
basis3 <- basis(res[[1]])
basis3 %>% 
  as.data.frame() %>% 
  rownames_to_column(var = "program_code") %>% 
  as_tibble() %>% 
  gather(topic, value, -program_code) %>% 
  left_join(pro_mst, by = "program_code") %>% 
  group_by(topic) %>% 
  mutate(rank = row_number(desc(value))) %>% 
  filter(rank < 21) %>% 
  select( -program_code, -n, -value) %>% 
  spread(topic, program_name) %>% 
  datatable(class = 'cell-border stripe',
            rownames = FALSE,
            extensions = 'FixedColumns',
            options = list(scrollX = TRUE, scrollCollapse = TRUE
  ))
```


### 基底ベクトル4個

- 放送局で分かれ始めた？

```{r table4}
basis4 <- basis(res[[2]])
basis4 %>% 
  as.data.frame() %>% 
  rownames_to_column(var = "program_code") %>% 
  as_tibble() %>% 
  gather(topic, value, -program_code) %>% 
  left_join(pro_mst, by = "program_code") %>% 
  group_by(topic) %>% 
  mutate(rank = row_number(desc(value))) %>% 
  filter(rank < 101) %>% 
  select( -program_code, -n, -value) %>% 
  spread(topic, program_name) %>% 
  datatable(class = 'cell-border stripe',
            rownames = FALSE,
            extensions = 'FixedColumns',
            options = list(scrollX = TRUE, scrollCollapse = TRUE
  ))
```

### 基底ベクトル5個

- トピック2と4が綺麗に抜けてる
- 子供向けトピックとNHKトピック
- それ以外はよく分からん
- トピック5はテレ朝？

```{r table5}
basis5 <- basis(res[[3]])
basis5 %>% 
  as.data.frame() %>% 
  rownames_to_column(var = "program_code") %>% 
  as_tibble() %>% 
  gather(topic, value, -program_code) %>% 
  left_join(pro_mst, by = "program_code") %>% 
  group_by(topic) %>% 
  mutate(rank = row_number(desc(value))) %>% 
  filter(rank < 101) %>% 
  select( -program_code, -n, -value) %>% 
  spread(topic, program_name) %>% 
  datatable(class = 'cell-border stripe',
            rownames = FALSE,
            extensions = 'FixedColumns',
            options = list(scrollX = TRUE, scrollCollapse = TRUE
  ))
```


### 基底ベクトル6個

- 日テレトピック出現（トピック4）
- トピック3はフジテレビか
- トピック1は 人気 & 夜報道 番組という感じ

```{r table6}
basis6 <- basis(res[[4]])
basis6 %>% 
  as.data.frame() %>% 
  rownames_to_column(var = "program_code") %>% 
  as_tibble() %>% 
  gather(topic, value, -program_code) %>% 
  left_join(pro_mst, by = "program_code") %>% 
  group_by(topic) %>% 
  mutate(rank = row_number(desc(value))) %>% 
  filter(rank < 101) %>% 
  select( -program_code, -n, -value) %>% 
  spread(topic, program_name) %>% 
  datatable(class = 'cell-border stripe',
            rownames = FALSE,
            extensions = 'FixedColumns',
            options = list(scrollX = TRUE, scrollCollapse = TRUE
  ))
```


### 基底ベクトル7個


```{r table7}
basis7 <- basis(res[[5]])
basis7 %>% 
  as.data.frame() %>% 
  rownames_to_column(var = "program_code") %>% 
  as_tibble() %>% 
  gather(topic, value, -program_code) %>% 
  left_join(pro_mst, by = "program_code") %>% 
  group_by(topic) %>% 
  mutate(rank = row_number(desc(value))) %>% 
  filter(rank < 21) %>% 
  select( -program_code, -n, -value) %>% 
  spread(topic, program_name) %>% write_csv("data/table/nmf7.csv")
  datatable(class = 'cell-border stripe',
            rownames = FALSE,
            extensions = 'FixedColumns',
            options = list(scrollX = TRUE, scrollCollapse = TRUE
  ))
```


### 基底ベクトル8個


```{r table8}
basis8 <- basis(res[[6]])
basis8 %>% 
  as.data.frame() %>% 
  rownames_to_column(var = "program_code") %>% 
  as_tibble() %>% 
  gather(topic, value, -program_code) %>% 
  left_join(pro_mst, by = "program_code") %>% 
  group_by(topic) %>% 
  mutate(rank = row_number(desc(value))) %>% 
  filter(rank < 101) %>% 
  select( -program_code, -n, -value) %>% 
  spread(topic, program_name) %>% write_csv("data/table/nmf8.csv")
  datatable(class = 'cell-border stripe',
            rownames = FALSE,
            extensions = 'FixedColumns',
            options = list(scrollX = TRUE, scrollCollapse = TRUE
  ))
```


### 基底ベクトル9個


```{r table9}
basis9 <- basis(res[[7]])
basis9 %>% 
  as.data.frame() %>% 
  rownames_to_column(var = "program_code") %>% 
  as_tibble() %>% 
  gather(topic, value, -program_code) %>% 
  left_join(pro_mst, by = "program_code") %>% 
  group_by(topic) %>% 
  mutate(rank = row_number(desc(value))) %>% 
  filter(rank < 101) %>% 
  select( -program_code, -n, -value) %>% 
  spread(topic, program_name) %>% write_csv("data/table/nmf9.csv")
  datatable(class = 'cell-border stripe',
            rownames = FALSE,
            extensions = 'FixedColumns',
            options = list(scrollX = TRUE, scrollCollapse = TRUE)
  )
```



## 視聴者に注目

$k=7$を例にとり，各トピックに何人の視聴者が属するかを以下に示す  
各視聴者にもっとも寄与する共起パターンを抽出すると解釈できる

```{r count_topic}
coef(res[[6]]) %>% 
  apply(2, function(x) which(x == max(x))) %>% 
  tibble(topic = .) %>% 
  ggplot(aes(factor(topic)))+
  geom_bar(colour = "blue", fill = "skyblue")+
  labs(x = "topic", title = "各世帯のメイントピック")
ggsave("report/fig/house_topic.png", width=5, height=5)
```

推定された係数の散布図をいかに示す．  
スパースなトピックとそうでないトピックがある  

- 下三角が散布図
- 対角が各トピックのカーネル密度
- 上三角が2dカーネル密度

```{r coef_pairplot}
coef(res[[6]]) %>% 
  t() %>% 
  as_tibble() %>% 
  ggpairs(upper = list(continuous = "density", combo = "box_no_facet"))

```


## テレビ局に注目

```{r station_topic}
basis(res[[6]]) %>% 
  as.data.frame() %>% 
  rownames_to_column(var = "program_code") %>% 
  as_tibble() %>% 
  left_join(collect(distinct(program, station_code, program_code)),
            by = "program_code") %>% 
  gather(topic, value, -program_code, -station_code) %>% 
  group_by(station_code, topic) %>% 
  summarise(value = sum(value)) %>% 
  left_join(collect(sta), by = "station_code") %>% 
  ggplot(aes(station_jp, value))+
  geom_bar(stat="identity")+
  facet_wrap(~topic)+
  coord_flip()+
  labs(x = "放送局", title = "放送局ごとの各トピックへの寄与")
ggsave("report/fig/station_topic.png", width=5, height=5)
```

## 番組分類に注目

- V2があつくね？

```{r ban1_topic}
basis(res[[6]]) %>% 
  as.data.frame() %>% 
  rownames_to_column(var = "program_code") %>% 
  as_tibble() %>% 
  left_join(collect(distinct(program, ban_code1, program_code)),
            by = "program_code") %>% 
  gather(topic, value, -program_code, -ban_code1) %>% 
  group_by(ban_code1, topic) %>% 
  summarise(value = sum(value)) %>% 
  left_join(collect(ban1), by = "ban_code1") %>% 
  ggplot(aes(ban_code1_naiyou, value))+
  geom_bar(stat="identity")+
  facet_wrap(~topic)+
  coord_flip()+
  labs(title = "番組大分類ごとの各トピックへの寄与", x = "大分類")
ggsave("report/fig/ban1_topic.png", width=5, height=5)
```

## 中分類に注目

```{r ban2_topic}
basis(res[[6]]) %>% 
  as.data.frame() %>% 
  rownames_to_column(var = "program_code") %>% 
  as_tibble() %>% 
  left_join(collect(distinct(program, ban_code2, program_code)),
            by = "program_code") %>% 
  gather(topic, value, -program_code, -ban_code2) %>% 
  group_by(ban_code2, topic) %>% 
  summarise(value = sum(value)) %>% 
  left_join(collect(ban2), by = "ban_code2") %>% 
  ggplot(aes(ban_code2_naiyou, value))+
  geom_bar(stat="identity")+
  facet_wrap(~topic)+
  coord_flip()+
  labs(title = "番組中分類ごとの各トピックへの寄与", x = "中分類")
ggsave("report/fig/ban2_topic.png", width=6.5, height=6.5)
```

## VRクラスタに注目

図を作りたかっただけ

```{r profile_alluvium}
innov <- prof %>% 
  filter(qu_genre_code == 25, question_code == 4) %>% 
  select(house_num, answer, answer_code) %>% 
  collect() %>% 
  mutate(answer = str_remove_all(answer, pattern = " "))

coef7 <- coef(res[[5]])
apply(coef7, 2, function(x) which(x == max(x)) ) %>% 
  data.frame(topic = .) %>% 
  rownames_to_column(var = "house_num") %>% 
  as_tibble() %>% 
  mutate(house_num = as.integer(house_num)) %>% 
  left_join(innov, by = "house_num") %>% 
  drop_na(answer) %>% 
  mutate(answer = fct_reorder(answer, answer_code)) %>% 
  count(topic, answer) %>% 

  ggplot(aes(axis1 = answer, axis2 = topic, y = n)) +
  scale_x_discrete(limits = c("answer", "topic"), expand = c(.1, .05)) +
  geom_alluvium(aes(fill = answer), alpha=.7)+
  scale_fill_viridis_d()+
  geom_stratum()+ 
  geom_text(stat = "stratum", label.strata = TRUE, family = "HiraKakuPro-W3")+
  theme_classic(base_family = "HiraKakuPro-W3")
```

## 時間に着目
```{r}
tmp <- program %>% 
  select(station_code, program_code, program_start_time) %>% 
  collect()
basis(res[[6]]) %>% 
  as.data.frame() %>% 
  rownames_to_column(var = "program_code") %>% 
  as_tibble() %>% 
  left_join(tmp %>% 
              mutate(hour = hour(program_start_time)) %>% 
              count(program_code, program_name, hour) %>% 
              arrange(program_code, n) %>% 
              group_by(program_code) %>%  
              slice(1) %>% 
              ungroup(),
            by = "program_code") %>% 
  select(-program_name, -n) %>% 
  gather(topic, value, -program_code, -hour) %>% 
  group_by(topic, hour) %>% 
  summarise(value = sum(value)) %>% 
  ggplot(aes(hour, value))+
  geom_bar(stat = "identity")+
  facet_wrap(~topic)+
  labs(title = "放送開始時間帯ごとの各トピックへの寄与", x = "時刻")
ggsave("report/fig/hour_topic.png", width=5, height=5)
```

```{r}
code_rate <- tmp %>% 
  left_join(watch_rate, by = c("station_code", "program_start_time"))%>% 
  group_by(program_code) %>% 
  summarise(watch_rate = mean(all_watch_rate, na.rm=TRUE)) 

basis(res[[6]]) %>% 
  apply(1, function(x) which(x == max(x))) %>% 
  data.frame(topic=.) %>% 
  rownames_to_column(var = "program_code") %>% 
  as_tibble() %>% 
  right_join(code_rate, by = "program_code") %>% 
  drop_na() %>% 
  ggplot(aes(watch_rate))+
  geom_histogram()+
  scale_x_continuous(limits = c(0,0.13))+
  facet_wrap(~topic)+
  labs(title = "各トピックの視聴率分布", x = "視聴率")
ggsave("report/fig/watch_rate_topic.png", width=5, height=5)
  
```

## トピックの相関

```{r corrr}
library(corrr)
corrr::correlate(basis(res[[6]])) %>% 
  kable()
```


# 考察・まとめ

## まとめ

- テレビ視聴におけるTF-IDFを定義して，NMFした

## 考察

- 特にない
- 報道番組の傾向が強い
- 報道番組は別でやったほうが良いかも
- もしくは，TF-IDFの定義が良くないか

## 感想

- 最近テキストマイニング興味あって，**やってみたかっただけ**
- 正直，テレビをあまり見ないので**ドメイン知識がない**
- 結果の解釈が難しくて，**何か気づいたら教えていただきたい**
- 基底ベクトル数10~15は今計算中
